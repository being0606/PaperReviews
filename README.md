# Reviewed Papers Summary

This document provides an overview of the research papers reviewed, organized by detailed research fields. Each section includes a table with the paper's review date, publication venue, published year, and a link to the presentation.

---

## 1. Pretrained Transformer Models (T5, BART, BERT, LLaMA3)

Papers discussing pretraining strategies and unified text-to-text frameworks, which have significantly influenced NLP.

| #   | Paper Title                                                                                                           | Review Date | Conference / Venue | Published Year | Link                                                                                                         |
| --- | --------------------------------------------------------------------------------------------------------------------- | ----------- | ------------------ | -------------- | ------------------------------------------------------------------------------------------------------------ |
| 1   | **Seq2Seq with Attention**                                                                                            | 2024.06.29  | ICLR (Assumed)     | 2015           | [Link](https://docs.google.com/presentation/d/1-iop7-Fl1rHyqmk_oOCYySII1ZMJ_5R5A8Il8RNtypw/edit#slide=id.p)  |
| 2   | **Attention Is All You Need**                                                                                         | 2025.01.17  | NeurIPS            | 2017           | [Link](https://docs.google.com/presentation/d/1Ot4-j7qjnmUXUFDz4lnPO5yzspzc44KSsF6qlBqaQYQ/edit?usp=sharing) |
| 3   | **BERT: Bidirectional Encoder Representations from Transformers**                                                     | 2025.01.21  | NAACL              | 2019           | [Link](https://docs.google.com/presentation/d/1jXnY-XUmqbDP-8S07ohzwKElEkweXOiZ9eEZu5x83L8/edit?usp=sharing) |
| 4   | **BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension** | 2025.01.30  | ACL (Preprint)     | 2019           | (https://docs.google.com/presentation/d/1G3L3qRQHZFukr5XntiWswpIZBZ15vhU4A8OAL7bvTwY/edit?usp=sharing) |
| 5   | **Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**                                 | 2025.01.25  | arXiv / JMLR       | 2019           | (https://docs.google.com/presentation/d/1s9Us2b5gyM_BHapcTuirmDaf6MmvA2Thswg2CS2Jg7o/edit?usp=sharing) |
| 6   | **The LLaMA 3 Herd of Model**                                                                                         | 2025.02.24  | N/A                | 2024           | [Link](https://docs.google.com/presentation/d/1YpTnPfxIb3cOoVC9htyeNhi6Y9-aefe_FSrMrlUrfsc/edit#slide=id.p)  |

---

## 2. MoE / Scalable Architectures

This section covers research on sparsely-gated and mixture-of-experts architectures, focusing on scalable deep learning models.

| #   | Paper Title                                                                         | Review Date | Conference / Venue | Published Year | Link                                                                                                         |
| --- | ----------------------------------------------------------------------------------- | ----------- | ------------------ | -------------- | ------------------------------------------------------------------------------------------------------------ |
| 1   | **Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer** | 2025.02.11  | ICLR               | 2017           | [Link](https://docs.google.com/presentation/d/13UgUTVf9Q6mWVIRAn1f0z6UXIe7-ffRQoYmWyGYHlds/edit?usp=sharing) |
| 2   | **LoftQ: LoRA-Fine-Tuning-Aware Quantization**                                      | 2025.02.19  | ICLR               | 2023           | [Link](https://docs.google.com/presentation/d/1tZOsxXaG-ZXeiW4eDmvEqxX6DOCKMqCcSTCFYAQPSvA/edit?usp=sharing) |

---

## 3. Reinforcement Learning for Human Feedback (RLHF)

This section focuses on preference optimization techniques used in fine-tuning language models to align their behavior with human preferences.

| #   | Paper Title                                                                        | Review Date | Conference / Venue | Published Year | Link                                                                                                         |
| --- | ---------------------------------------------------------------------------------- | ----------- | ------------------ | -------------- | ------------------------------------------------------------------------------------------------------------ |
| 1   | **Direct Preference Optimization: Your Language Model is Secretly a Reward Model** | 2025.02.25  | NeurIPS            | 2023           | [Link](https://docs.google.com/presentation/d/15VFKz5KmtCisZk_eJR2lElSIlVobWm1Ekmod4z7qpvU/edit?usp=sharing) |

---

### Summary

This document provides a structured reference for reviewed papers, categorized by major research topics. The summaries highlight key contributions and methodologies in pretrained transformer models, scalable architectures, and reinforcement learning for human feedback.
